# ğŸ¤– AI Modeling

> íŠ¸ìœ— ê¸°ë°˜ IT ê¸°ì—… ê°ì„± ë¶„ì„ì„ ìœ„í•œ AI ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co)
[![Weights & Biases](https://img.shields.io/badge/W&B-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black)](https://wandb.ai)

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” **íŠ¸ìœ— ë°ì´í„°**ë¥¼ í™œìš©í•˜ì—¬ IT ê¸°ì—…ì— ëŒ€í•œ ëŒ€ì¤‘ì˜ ê°ì„±ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ì£¼ê°€ ì§€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ì— í™œìš©í•˜ëŠ” AI ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” ëª©í‘œ
- LDA í† í”½ ëª¨ë¸ë§ì„ í†µí•œ ì£¼ìš” í† í”½ ì¶”ì¶œ
- RoBERTa ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•œ ê°ì„± ë¶„ë¥˜
- ê°ì„± ì ìˆ˜ì™€ ì£¼ê°€ ì§€ìˆ˜(S&P500, NASDAQ100) ê°„ ìƒê´€ê´€ê³„ ë¶„ì„

---

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
AI Modeling/
â”œâ”€â”€ ğŸ“ lda-topic-sentiment/     # LDA í† í”½ ëª¨ë¸ë§ + ê°ì„± ë¶„ì„
â”‚   â”œâ”€â”€ lda.py                  # LDA ëª¨ë¸ í•™ìŠµ
â”‚   â”œâ”€â”€ sentiment.py            # ê°ì„± ë¶„ì„
â”‚   â”œâ”€â”€ get_score.py            # ê°ì„± ì ìˆ˜ ê³„ì‚°
â”‚   â””â”€â”€ etc/
â”‚       â”œâ”€â”€ correlation.py      # Pearson ìƒê´€ê³„ìˆ˜ ê³„ì‚°
â”‚       â”œâ”€â”€ preproc.py          # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
â”‚       â””â”€â”€ utils.py            # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚
â”œâ”€â”€ ğŸ“ tweet-sa-roberta/        # RoBERTa ê°ì„± ë¶„ì„ ëª¨ë¸
â”‚   â”œâ”€â”€ train.py                # ëª¨ë¸ í•™ìŠµ
â”‚   â”œâ”€â”€ test.py                 # ëª¨ë¸ í‰ê°€
â”‚   â”œâ”€â”€ sweep/                  # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
â”‚   â”‚   â””â”€â”€ wandb_sweep.ipynb   # W&B Sweep ì‹¤í—˜
â”‚   â””â”€â”€ util/
â”‚       â”œâ”€â”€ models.py           # ëª¨ë¸ ì •ì˜
â”‚       â”œâ”€â”€ dataset.py          # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
â”‚       â””â”€â”€ dataloader.py       # ë°ì´í„°ë¡œë”
â”‚
â”œâ”€â”€ ğŸ“ topic-modeling/          # í† í”½ ëª¨ë¸ë§ ë‹¨ë… ëª¨ë“ˆ
â”‚   â”œâ”€â”€ train.py                # í† í”½ ëª¨ë¸ í•™ìŠµ
â”‚   â”œâ”€â”€ get_topic.py            # í† í”½ ì¶”ì¶œ
â”‚   â””â”€â”€ get_model.py            # ëª¨ë¸ ë¡œë“œ
â”‚
â”œâ”€â”€ ğŸ“ mlm-modeing/             # Masked Language Modeling
â”‚   â”œâ”€â”€ mlm.sh                  # MLM í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ mlm_t5.sh               # T5 ê¸°ë°˜ MLM
â”‚
â””â”€â”€ ğŸ““ Senty_Project.ipynb      # ì „ì²´ íŒŒì´í”„ë¼ì¸ ë…¸íŠ¸ë¶
```

---

## ğŸ”¬ ê¸°ìˆ  ìŠ¤íƒ

### í† í”½ ëª¨ë¸ë§
| ê¸°ìˆ  | ì„¤ëª… |
|------|------|
| **LDA (Latent Dirichlet Allocation)** | íŠ¸ìœ—ì—ì„œ ì ì¬ í† í”½ ì¶”ì¶œ |
| **Gensim** | í† í”½ ëª¨ë¸ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ |

### ê°ì„± ë¶„ì„
| ê¸°ìˆ  | ì„¤ëª… |
|------|------|
| **RoBERTa-base** | ì‚¬ì „í•™ìŠµëœ Transformer ëª¨ë¸ |
| **Fine-tuning** | íŠ¸ìœ— ê°ì„± ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¯¸ì„¸ì¡°ì • |
| **3-class Classification** | ê¸ì • / ë¶€ì • / ì¤‘ë¦½ ë¶„ë¥˜ |

### ìƒê´€ê´€ê³„ ë¶„ì„
| ê¸°ìˆ  | ì„¤ëª… |
|------|------|
| **Pearson ìƒê´€ê³„ìˆ˜** | `scipy.stats.pearsonr` ì‚¬ìš© |
| **Window Size** | 3ì¼, 5ì¼, 7ì¼ ì´ë™ í‰ê·  ì ìš© |

---

## ğŸ“Š ë¶„ì„ íŒŒì´í”„ë¼ì¸

```mermaid
graph LR
    A[íŠ¸ìœ— ìˆ˜ì§‘] --> B[í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬]
    B --> C[LDA í† í”½ ëª¨ë¸ë§]
    C --> D[í† í”½ë³„ ë¶„ë¥˜]
    D --> E[RoBERTa ê°ì„± ë¶„ì„]
    E --> F[ì¼ë³„ ê°ì„± ì ìˆ˜]
    F --> G[ì£¼ê°€ ì§€ìˆ˜ ìƒê´€ê´€ê³„]
```

### 1ï¸âƒ£ LDA í† í”½ ëª¨ë¸ë§
```python
# 9ê°œ í† í”½ ì¶”ì¶œ
from gensim.models import LdaModel

lda_model = LdaModel(
    corpus=corpus,
    num_topics=9,
    id2word=dictionary,
    passes=15
)
```

### 2ï¸âƒ£ RoBERTa ê°ì„± ë¶„ì„
```python
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(
    "roberta-base",
    num_labels=3  # ê¸ì •, ë¶€ì •, ì¤‘ë¦½
)
```

### 3ï¸âƒ£ ì¼ë³„ ê°ì„± ì ìˆ˜ ê³„ì‚°
```python
# ê°ì„± ì ìˆ˜ ê³µì‹
Score = ((ê¸ì • ìˆ˜ - ë¶€ì • ìˆ˜) / ì „ì²´ íŠ¸ìœ—) Ã— (1 - ì¤‘ë¦½ ë¹„ìœ¨)
```

### 4ï¸âƒ£ Pearson ìƒê´€ê³„ìˆ˜
```python
from scipy import stats

correlation, p_value = stats.pearsonr(sentiment_scores, stock_index)
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### í™˜ê²½ ì„¤ì •
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r lda-topic-sentiment/requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export HF_TOKEN="your_huggingface_token"
export WANDB_TOKEN="your_wandb_token"
```

### LDA í† í”½ ëª¨ë¸ë§
```bash
cd lda-topic-sentiment
python main.py
```

### RoBERTa ê°ì„± ë¶„ì„ í•™ìŠµ
```bash
cd tweet-sa-roberta
bash train.sh
```

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (W&B Sweep)
```bash
cd tweet-sa-roberta/sweep
# Jupyter Notebook ì‹¤í–‰
jupyter notebook wandb_sweep.ipynb
```

---

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼

### ê°ì„± ë¶„ì„ ëª¨ë¸ ì„±ëŠ¥
| Metric | Score |
|--------|-------|
| **Accuracy** | 72.3% |
| **F1-Score** | 0.71 |

### ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼
| í† í”½ | S&P500 ìƒê´€ê³„ìˆ˜ | NASDAQ100 ìƒê´€ê³„ìˆ˜ |
|------|----------------|-------------------|
| GPU | **-0.68** | -0.62 |
| Apple | -0.45 | -0.41 |
| AI/ML | -0.38 | -0.35 |

> ğŸ’¡ **ì£¼ìš” ë°œê²¬**: GPU í† í”½ì—ì„œ ê°€ì¥ ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„(-0.68)ê°€ ë°œê²¬ë¨

---

## ğŸ“¦ ë°ì´í„°ì…‹

| ë°ì´í„° | ì„¤ëª… |
|--------|------|
| **ìˆ˜ì§‘ ê¸°ê°„** | 2023.05.23 ~ 2023.06.15 |
| **ì´ íŠ¸ìœ— ìˆ˜** | ~50,000ê°œ |
| **ë¶„ì„ ëŒ€ìƒ** | 5ê°œ IT ê¸°ì—… |
| **ì¶”ì¶œ í† í”½** | 9ê°œ |

---

## ğŸ”— ê´€ë ¨ ë ˆí¬ì§€í† ë¦¬

- [ğŸ“Š Frontend](https://github.com/inisw-8/frontend) - React ëŒ€ì‹œë³´ë“œ
- [ğŸ–¥ï¸ Web Server](https://github.com/inisw-8/web-server) - FastAPI ë°±ì—”ë“œ
- [ğŸ“¥ Data Gathering](https://github.com/inisw-8/data-gathering) - ë°ì´í„° ìˆ˜ì§‘

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

---

<div align="center">

**Senty Project** - íŠ¸ìœ— ê¸°ë°˜ IT ê¸°ì—… ê°ì„± ë¶„ì„ ğŸ“Š

</div>

